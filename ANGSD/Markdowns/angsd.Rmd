---
title: "ANGSD"
output: 
  github_document:
    toc: true
    toc_depth: 3
date: "2024-01-17"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Genotype Likelihoods
## Generating a sites file

Before running the genotype likelihood analysis, a sites file should be prepared. This is a file containing the sites to include in the analysis. Bed files should be first converted to angsd format, as they are differently indexed.

To convert a bed file (generated by the GenErode pipeline) to angsd file and index the file:

```{bash, eval = FALSE}
awk '{print $1"\t"$2+1"\t"$3}' GCF_016772045.1_ARS-UI_Ramb_v2.0_genomic.repma.autos.bed > GCF_016772045.1_ARS-UI_Ramb_v2.0_genomic.repma.autos.angsd.sites
angsd sites index GCF_016772045.1_ARS-UI_Ramb_v2.0_genomic.repma.autos.angsd.sites
```
Which generates following three files:  

* `GCF_016772045.1_ARS-UI_Ramb_v2.0_genomic.repma.autos.angsd.sites` 
* `GCF_016772045.1_ARS-UI_Ramb_v2.0_genomic.repma.autos.angsd.bin`
* `GCF_016772045.1_ARS-UI_Ramb_v2.0_genomic.repma.autos.angsd.idx`

In this reference, repeats are masked ("repma") and only autosomes ("autos") are used.

## Generating genotype likelihood files

```{bash, eval = FALSE}
INPUT="Mouflon_domestic"
DIR="/proj/snic2020-2-10/private/Analyses/marianne/PROJECTS/EuropeanMouflon/ANGSD"
INPUTFILE="/proj/snic2020-2-10/private/Analyses/marianne/PROJECTS/EuropeanMouflon/ANGSD/${INPUT}.list"
SITESFILE="/proj/snic2020-2-10/private/Analyses/marianne/PROJECTS/EuropeanMouflon/ANGSD/GCF_016772045.1_ARS-UI_Ramb_v2.0_genomic.repma.autos.angsd.file"
REFERENCE="/proj/snic2020-2-10/private/Data/Non-Human/Animals/sheep/ref_seqs/ARS-UI_Ramb_v2.0/RepeatMasker/GCF_016772045.1_ARS-UI_Ramb_v2.0_genomic.fna"

angsd -bam $INPUTFILE \
  -GL 1 \
  -nThreads 16 \
  -doGlf 2 \
  -doMajorMinor 1 \
  -SNP_pval 1e-6 \
  -doMaf 1 \
  -minMapQ 30 -minQ 30 \
  -uniqueOnly 1 -remove_bads 1 \
  -sites $SITESFILE \
	-ref $REFERENCE \
	-out $DIR/$INPUT

```

Which generates following files:  

* `Mouflon_domestic.beagle.gz` 
* `Mouflon_domestic.mafs.gz`

Parameters:

* `-GL`: Method to estimate genotype likelihood from bam files. Four different methods are available.
    + 1. SAMtools model
    + 2. GATK model
* `-doGlf`: Output the log genotype likelihoods to a file
    + 0. Don't output the genotype likelihoods
    + 1. Binary all 10 log genotype likelihood
    + 2. Beagle genotype likelihood format
* `-doMajorMinor`: Infer major and minor allele using a maximum likelihood approach ()
    + 1. Infer major and minor from GL
    + 2. Infer major and minor from allele counts
* `-SNP_pval 1e-6 `: Remove sites with a pvalue larger
* `-doMaf`: Calculate persite frequencies ('.mafs.gz')
    + 1. Frequency (fixed major and minor)
* `-minMapQ`: Minimum mapQ quality.
* `-minQ`: Minimum base quality score.
* `-uniqueOnly`: Remove reads that have multiple best hits. 0 no (default), 1 remove.
* `-remove_bads`: Same as the samtools flags -x which removes read with a flag above 255 (not primary, failure and duplicate reads). 0 no , 1 remove (default).
* `-sites`: File containing the sites to include in analysis (chr pos).

#### More resources:
https://www.popgen.dk/angsd/index.php/Genotype_Likelihoods \
https://www.popgen.dk/angsd/index.php/Major_Minor \
https://www.popgen.dk/angsd/index.php/Allele_Frequencies

# ngsLD pruning

Before running PCangsd and NgsAdmixture, the data is first LD-pruned using the program [ngsLD](https://github.com/fgvieira/ngsLD)

## Prepare the input files
ngsLD requires two input files. 

1. `--geno FILE`: input file with genotypes, genotype likelihoods or genotype posterior probabilities. A `beagle` formatted genotype likelihood file generated from ANGSD (`-doGlf 2`) can be inputted into ngsLD after the header row and the first three columns (i.e. positions, major allele, minor allele) are removed.
2. `--pos FILE`: input file with site coordinates (one per line), where the 1st column stands for the chromosome/contig and the 2nd for the position (bp). This file is generated by selecting the first two columns of the `mafs` file outputted by ANGSD, with the header removed. One convenient way to generate this is by selecting the first two columns of the `mafs` file outputted by ANGSD, with the header removed. 

```{bash eval = FALSE}
#!/bin/bash -l

INPUT="Mouflon_domestic"
INDIR="/proj/snic2020-2-10/private/Analyses/marianne/PROJECTS/EuropeanMouflon/ANGSD"
OUTDIR="/proj/snic2020-2-10/private/Analyses/marianne/PROJECTS/EuropeanMouflon/ngsLD"

## Prepare a geno file
zcat $INDIR/${INPUT}.beagle.gz cut -f 4- | tail -n +2 | gzip  > $OUTDIR/${INPUT}.geno.beagle.gz

## Prepare a pos file
zcat $INDIR/${INPUT}.mafs.gz | cut -f 1,2 | tail -n +2 | gzip > $OUTDIR/${INPUT}.pos.gz

```

## Run ngsLD
$\color{red}{\text{IMPORTANT}}$: make sure to not set both `max_kb_dist` and `max_snp_dist` to 0. ngsLD will output all comparisons, resulting in humongous files (several Tb)

--> current problem: with max_kb_dist = 1000 and max_snp_dist = 0, analysis does not seem to finnish 

```{bash eval = FALSE}
#!/bin/bash -l

zcat $OUTDIR/${INPUT}.geno.beagle.gz | grep ${CHROM} | gzip > $OUTDIR/${INPUT}.geno.beagle.${CHROM}.gz
zcat $OUTDIR/${INPUT}.pos.gz | grep ${CHROM} | gzip > $OUTDIR/${INPUT}.pos.${CHROM}.gz

N=$(zcat $OUTDIR/${INPUT}.pos.${CHROM}.gz | wc -l)

ngsLD \
--geno ${OUTDIR}/${INPUT}.geno.beagle.${CHROM}.gz \
--pos ${OUTDIR}/${INPUT}.pos.${CHROM}.gz \
--probs \
--n_ind 76 \
--n_sites ${N} \
--max_kb_dist 0 \
--n_threads 8 \
--min_maf 0.05 --max_snp_dist 100 \
--out ${OUTDIR}/${INPUT}.${CHROM}.ld 
```

ngsLD parameters:

* `--probs`: add to indicate that input are genotype likelihoods
* `--max_kb_dist DOUBLE`: maximum distance between SNPs (in Kb) to calculate LD. Set to 0(zero) to disable filter
* `--max_snp_dist INT`: maximum distance between SNPs (in number of SNPs) to calculate LD. Set to 0 (zero) to disable filter

## LD pruning
### Run ngsLD scripts

* `--max_kb_dist INT`: Maximum distance between nodes (ie. SNPs, input file 3rd column) to assume they are connected
* `--min_weight FLOAT`: Minimum weight (in --weight_field) of an edge to assume nodes are connected (the weight refers to the LD estimate between two SNPs)
* `--out FILE`: Path to output file [STDOUT]

<br>

```{bash eval = FALSE}

perl prune_graph.pl \
--in_file $OUTDIR/${INPUT}.ld \
--max_kb_dist 2000 \
--min_weight 0.5 \
--out $OUTDIR/${INPUT}.unsampled.id

```

<br>

### Generate an LD-pruned SNP list for ANGSD

R is used to generate an LD-pruned SNP list in a format that can be used by ANGSD for downstream analyses.

```{r eval=FALSE}


pruned_position <- as.integer(gsub("GCF_016772045.1_ARS-UI_Ramb_v2.0_genomic.repma.autos:", "", readLines(paste0(basedir, "$OUTDIR/${INPUT}.unsampled.id"))))

snp_list <- read.table(paste0(basedir, "$INDIR/${INPUT}.mafs.gz"), stringsAsFactors = F, header = T)[,1:4]

pruned_snp_list <- snp_list[snp_list$position %in% pruned_position, ]
  
write.table(pruned_snp_list, paste0(basedir, "${OUTDIR}/${INPUT}.LDpruned_snps.list"), col.names = F, row.names = F, quote = F, sep = "\t")

```

## PCangsd
## NgsAdmix
### Determine optimal K

```{R eval = FALSE}

#read in the data
data<-list.files("~/Library/CloudStorage/OneDrive-Personal/CTS/Rscripts/ANGSD/Mouflon_domestic_NgsAdmix/", pattern = ".log", full.names = T)

#use lapply to read in all our log files at once
bigData<-lapply(1:6, FUN = function(i) readLines(data[i]))

# find the line that starts with "best like=" or just "b"
library(stringr)

#this will pull out the line that starts with "b" from each file and return it as a list
foundset<-sapply(1:6, FUN= function(x) bigData[[x]][which(str_sub(bigData[[x]], 1, 1) == 'b')])

#make a dataframe with an index 1:7, this corresponds to our K values
logs<-data.frame(K = rep(2:7, each=1))

#add to it our likelihood values
logs$like<-as.vector(as.numeric( sub("\\D*(\\d+).*", "\\1", foundset) ))

#and now we can calculate our delta K and probability
tapply(logs$like, logs$K, FUN= function(x) mean(abs(x))/sd(abs(x)))

```
